## Queue-Based Load Leveling

### Какую боль лечит
Всплески нагрузки (импорты, массовые загрузки, долгие вызовы 3rd-party) бьют по критичным частям системы и роняют отклик для клиентов. Очередь ставится между отправителем и обработчиком, чтобы смягчить пики: продьюсер пишет быстро, воркеры едят в своём темпе.

### Когда применять
- Нагрузки приходят волнами, а время ответа фронта/клиента важно.
- Есть долгие или нестабильные операции (webhook, интеграция).
- Хотим изолировать ядро от спайков, но не терять запросы.

### Поток
1) Продьюсер кладёт сообщение в очередь (быстро, без тяжёлой логики).
2) Очередь сохраняет и буферизует (durable, с ack).
3) Воркеры читают и обрабатывают в своём темпе.
4) При всплеске растёт длина очереди, а не число 500 на фронте.

### Быстрый пример (PHP + RabbitMQ)
```php
// Продьюсер
$channel->basic_publish(new AMQPMessage(json_encode([
    'type' => 'import_product',
    'payload' => ['id' => 42]
])), 'imports');

// Консьюмер
$channel->basic_consume('imports', '', false, false, false, false,
    function (AMQPMessage $msg) {
        $job = json_decode($msg->getBody(), true);
        handleImport($job['payload']); // бизнес-логика
        $msg->ack(); // подтверждаем только после успешной обработки
    }
);
```
То же можно сделать через SQS, Redis Streams, Kafka, Beanstalkd или встроенные очереди фреймворка (Laravel Horizon, Symfony Messenger).

### Что важно настроить
- `durable` сообщения и `ack` после обработки, чтобы не терять данные.
- `prefetch` (например `prefetch=10`) — воркер не берёт больше, чем способен переварить.
- Горизонтальное масштабирование воркеров по метрике длины очереди.
- Idempotent обработка: повтор сообщений не должен ломать систему.
- DLQ (dead letter queue) для сообщений, которые не обработались после N попыток.

### Типичные грабли
- Записываем в очередь внутри одной транзакции с БД, но не используем outbox — при падении можем потерять сообщение или получить дубликат.
- Нет таймаута на обработку — “вечный” воркер держит сообщение, очередь залипает.
- Нет метрик по длине/времени ожидания — замечаем проблему, когда фронт уже горит.
- Неправильный размер батча: слишком большой — рост латентности, слишком маленький — высокий overhead.

### Как проверять в проде
- Метрики: длина очереди, время в очереди (enqueue -> dequeue), процент retry/DLQ.
- Алерты: “длина очереди > X за Y минут”, “доля DLQ > N%”, “нет потребления”.
- Трейсы/логи: `trace_id` передавать из продьюсера в воркер для связки.
