## Вопрос: ClickHouse

## Простой ответ
- Очень быстрая аналитика по большим таблицам за счёт колоночного хранения и сжатия.
- Хорош для логов/метрик/отчётов, но не для OLTP и транзакций.

## Ответ

### Что такое ClickHouse

ClickHouse -- это колоночная аналитическая СУБД (OLAP), разработанная в Яндексе для сервиса Яндекс.Метрика. Основная задача -- выполнение аналитических запросов (агрегации, фильтрация, группировка) по миллиардам строк за секунды. ClickHouse стал open-source в 2016 году и быстро набрал популярность благодаря выдающейся производительности на аналитических нагрузках.

### Почему ClickHouse быстрый: колоночное хранение

В традиционных строковых СУБД (PostgreSQL, MySQL) данные хранятся построчно: все столбцы одной строки лежат рядом на диске. В ClickHouse данные каждого столбца хранятся отдельно. Это даёт три ключевых преимущества:

1. **Чтение только нужных столбцов** -- запрос `SELECT avg(price) FROM orders` читает с диска только столбец `price`, игнорируя все остальные.
2. **Эффективное сжатие** -- данные одного типа в столбце сжимаются значительно лучше (однородные значения). Коэффициент сжатия 5-20x -- обычное дело.
3. **Векторные операции** -- обработка данных столбцами позволяет использовать SIMD-инструкции процессора и оптимизировать работу с CPU cache.

### Архитектура и ключевые концепции

| Концепция | Описание |
|-----------|----------|
| **MergeTree** | Основное семейство движков таблиц. Данные сортируются по PRIMARY KEY, хранятся в частях (parts), периодически мержатся в фоне |
| **Partitioning** | Логическое деление таблицы (обычно по дате/месяцу). Позволяет эффективно удалять старые данные (`DROP PARTITION`) |
| **Primary key** | Не уникальный! Определяет порядок сортировки данных в parts. Используется для sparse index |
| **Sparse index** | Индексируется каждая N-я строка (гранула, по умолчанию 8192 строки). Легковесный, помещается в RAM |
| **Materialized Views** | Автоматические агрегаты, обновляемые при вставке новых данных |
| **TTL** | Автоматическое удаление или перемещение данных по истечению срока |

### Движки таблиц

```
MergeTree           -- базовый движок, сортировка + сжатие
ReplacingMergeTree  -- дедупликация по ключу (eventual)
SummingMergeTree    -- автоматическое суммирование при merge
AggregatingMergeTree -- хранение промежуточных состояний агрегатов
CollapsingMergeTree -- "отмена" строк через sign (+1/-1)
ReplicatedMergeTree -- репликация через ZooKeeper/ClickHouse Keeper
Distributed         -- виртуальная таблица для шардированных запросов
```

### Пример: создание таблицы и запросы

```sql
-- Создание таблицы с партиционированием по месяцу
CREATE TABLE events (
    event_date Date,
    event_time DateTime,
    user_id    UInt64,
    event_type LowCardinality(String),
    url        String,
    duration   Float32
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(event_date)
ORDER BY (event_type, user_id, event_time)
TTL event_date + INTERVAL 90 DAY
SETTINGS index_granularity = 8192;

-- Вставка (обычно батчами по 10-100K+ строк)
INSERT INTO events VALUES
    ('2024-01-15', '2024-01-15 10:30:00', 42, 'page_view', '/products', 1.5),
    ('2024-01-15', '2024-01-15 10:31:00', 42, 'click', '/products/1', 0.3);

-- Аналитический запрос: топ событий за день
SELECT
    event_type,
    count() AS cnt,
    uniqExact(user_id) AS users,
    avg(duration) AS avg_dur
FROM events
WHERE event_date = '2024-01-15'
GROUP BY event_type
ORDER BY cnt DESC;

-- Materialized View для агрегации в реальном времени
CREATE MATERIALIZED VIEW events_daily_mv
ENGINE = SummingMergeTree()
ORDER BY (event_date, event_type)
AS SELECT
    event_date,
    event_type,
    count() AS hits,
    uniq(user_id) AS users
FROM events
GROUP BY event_date, event_type;
```

### ClickHouse vs традиционные СУБД

| Критерий | ClickHouse (OLAP) | PostgreSQL/MySQL (OLTP) |
|----------|-------------------|------------------------|
| Модель хранения | Колоночная | Строковая |
| Вставка | Батчами (1000+ строк) | Поштучно, транзакционно |
| UPDATE/DELETE | Мутации (async, тяжёлые) | Быстрые, транзакционные |
| Транзакции | Нет полноценных ACID | Полные ACID |
| Агрегации | Миллиарды строк/сек | Замедление на больших объёмах |
| JOIN | Поддержан, но ограниченно | Полная поддержка |
| Типичный запрос | `SELECT ... GROUP BY ... ORDER BY` | `INSERT/UPDATE/SELECT по PK` |

### Когда использовать ClickHouse

- **Веб-аналитика и продуктовая аналитика** -- подсчёт событий, воронки, когорты, retention.
- **Логирование и observability** -- хранение и анализ логов приложений, infrastructure metrics, APM.
- **BI и ad-hoc отчёты** -- интерактивные дашборды с фильтрами по произвольным измерениям.
- **Time-series данные** -- метрики серверов, IoT, финансовые данные (котировки).
- **Real-time analytics** -- Materialized Views позволяют обновлять агрегаты при каждой вставке.

### Когда НЕ использовать ClickHouse

- Частые UPDATE/DELETE отдельных строк (OLTP-нагрузка).
- Транзакционная логика (перевод средств, инвентарь).
- Запросы по ключу с очень низкой latency (< 1 мс) -- лучше Redis или обычная СУБД.
- Поштучная вставка с немедленной видимостью -- ClickHouse оптимизирован для батчевой вставки.

### Практические рекомендации

- **Вставляйте батчами**: минимум 1000 строк за INSERT, идеально 10-100K. Поштучная вставка создаёт множество мелких parts и деградирует производительность.
- **ORDER BY в таблице** -- самое важное решение при проектировании. Ставьте столбцы, по которым чаще всего фильтруете, в начало ORDER BY.
- **LowCardinality** -- используйте для строковых столбцов с небольшим числом уникальных значений (status, country, event_type). Ускоряет запросы в 2-10 раз.
- **Не нормализуйте** -- в OLAP денормализация (широкие таблицы) обычно лучше, чем JOIN.
- **Мониторинг**: следите за `system.merges`, `system.parts`, `system.query_log` для диагностики проблем.

## Примеры
```sql
SELECT event_type, count() AS cnt
FROM events
WHERE event_date >= today() - 7
GROUP BY event_type
ORDER BY cnt DESC;
```

## Доп. теория
- В ClickHouse основной ключ — это ключ сортировки (ORDER BY), он не обязан быть уникальным.
- Обновления/удаления выполняются через «мутации», поэтому они дороже, чем в OLTP‑СУБД.
